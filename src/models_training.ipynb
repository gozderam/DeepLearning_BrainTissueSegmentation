{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from models.basic_unet import BasicUNET\n",
    "from tqdm import tqdm\n",
    "from loader import load_BrainTissue_data\n",
    "from PIL import Image\n",
    "from models_training import save_params, train_network\n",
    "import configs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda:0'\n",
    "    print('Running on the GPU')\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    print(\"Running on the CPU\")\n",
    "\n",
    "TRAIN_IDX_START = 1\n",
    "TRAIN_IDX_STOP = 33\n",
    "VAL_IDX_START = 34\n",
    "VAL_IDX_STOP = 35\n",
    "\n",
    "get_model_path = lambda model_name, axis : f\"{configs.BASE_PATH}/trained_models/model_files/{model_name}_{axis}\"\n",
    "get_parms_path = lambda model_name, axis :  f\"{configs.BASE_PATH}/trained_models/model_params/{model_name}_{axis}_params\"\n",
    "get_loss_path = lambda model_name, axis : f\"{configs.BASE_PATH}/trained_models/model_losses/{model_name}_{axis}_loss\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 x Basic Unet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training basic_unet_test for axis X =====\n",
      "  Epoch: 0\n",
      "[epoch: 0, batches:     0 -    15] train loss: 0.859\n",
      "[epoch: 0, batches:    16 -    31] train loss: 0.299\n",
      "[epoch: 0, batches:    32 -    47] train loss: 0.223\n",
      "[epoch: 0, batches:    48 -    63] train loss: 0.211\n",
      "[epoch: 0, batches:    64 -    79] train loss: 0.199\n",
      "[epoch: 0, batches:    80 -    95] train loss: 0.215\n",
      "[epoch: 0, batches:    96 -   111] train loss: 0.203\n",
      "[epoch: 0, batches:   112 -   127] train loss: 0.185\n",
      "[epoch: 0, batches:   128 -   143] train loss: 0.184\n",
      "[epoch: 0, batches:   144 -   159] train loss: 0.172\n",
      "[epoch: 0, batches:   160 -   175] train loss: 0.169\n",
      "[epoch: 0, batches:   176 -   191] train loss: 0.155\n",
      "[epoch: 0, batches:   192 -   207] train loss: 0.158\n",
      "[epoch: 0, batches:   208 -   223] train loss: 0.150\n",
      "[epoch: 0, batches:   224 -   239] train loss: 0.152\n",
      "[epoch: 0, batches:   240 -   255] train loss: 0.134\n",
      "[epoch: 0, batches:   256 -   271] train loss: 0.131\n",
      "[epoch: 0, batches:   272 -   287] train loss: 0.129\n",
      "[epoch: 0, batches:   288 -   303] train loss: 0.128\n",
      "[epoch: 0, batches:   304 -   319] train loss: 0.121\n",
      "Training in epoch 0 finished. Train loss: 0.12050688918679953]\n",
      "[Validation in epoch 0 finished. Validation loss: 0.168]\n",
      "  Epoch: 1\n",
      "[epoch: 1, batches:     0 -    15] train loss: 0.120\n",
      "[epoch: 1, batches:    16 -    31] train loss: 0.112\n",
      "[epoch: 1, batches:    32 -    47] train loss: 0.105\n",
      "[epoch: 1, batches:    48 -    63] train loss: 0.115\n",
      "[epoch: 1, batches:    64 -    79] train loss: 0.116\n",
      "[epoch: 1, batches:    80 -    95] train loss: 0.115\n",
      "[epoch: 1, batches:    96 -   111] train loss: 0.106\n",
      "[epoch: 1, batches:   112 -   127] train loss: 0.105\n",
      "[epoch: 1, batches:   128 -   143] train loss: 0.103\n",
      "[epoch: 1, batches:   144 -   159] train loss: 0.103\n",
      "[epoch: 1, batches:   160 -   175] train loss: 0.104\n",
      "[epoch: 1, batches:   176 -   191] train loss: 0.096\n",
      "[epoch: 1, batches:   192 -   207] train loss: 0.092\n",
      "[epoch: 1, batches:   208 -   223] train loss: 0.092\n",
      "[epoch: 1, batches:   224 -   239] train loss: 0.088\n",
      "[epoch: 1, batches:   240 -   255] train loss: 0.096\n",
      "[epoch: 1, batches:   256 -   271] train loss: 0.090\n",
      "[epoch: 1, batches:   272 -   287] train loss: 0.082\n",
      "[epoch: 1, batches:   288 -   303] train loss: 0.085\n",
      "[epoch: 1, batches:   304 -   319] train loss: 0.081\n",
      "Training in epoch 1 finished. Train loss: 0.08095222874544561]\n",
      "[Validation in epoch 1 finished. Validation loss: 0.142]\n",
      "  Epoch: 2\n",
      "[epoch: 2, batches:     0 -    15] train loss: 0.087\n",
      "[epoch: 2, batches:    16 -    31] train loss: 0.077\n",
      "[epoch: 2, batches:    32 -    47] train loss: 0.084\n",
      "[epoch: 2, batches:    48 -    63] train loss: 0.083\n",
      "[epoch: 2, batches:    64 -    79] train loss: 0.086\n",
      "[epoch: 2, batches:    80 -    95] train loss: 0.080\n",
      "[epoch: 2, batches:    96 -   111] train loss: 0.077\n",
      "[epoch: 2, batches:   112 -   127] train loss: 0.075\n",
      "[epoch: 2, batches:   128 -   143] train loss: 0.076\n",
      "[epoch: 2, batches:   144 -   159] train loss: 0.083\n",
      "[epoch: 2, batches:   160 -   175] train loss: 0.081\n",
      "[epoch: 2, batches:   176 -   191] train loss: 0.084\n",
      "[epoch: 2, batches:   192 -   207] train loss: 0.072\n",
      "[epoch: 2, batches:   208 -   223] train loss: 0.075\n",
      "[epoch: 2, batches:   224 -   239] train loss: 0.073\n",
      "[epoch: 2, batches:   240 -   255] train loss: 0.076\n",
      "[epoch: 2, batches:   256 -   271] train loss: 0.070\n",
      "[epoch: 2, batches:   272 -   287] train loss: 0.077\n",
      "[epoch: 2, batches:   288 -   303] train loss: 0.076\n",
      "[epoch: 2, batches:   304 -   319] train loss: 0.080\n",
      "Training in epoch 2 finished. Train loss: 0.07966041751205921]\n",
      "[Validation in epoch 2 finished. Validation loss: 0.128]\n",
      "  Epoch: 3\n",
      "[epoch: 3, batches:     0 -    15] train loss: 0.072\n",
      "[epoch: 3, batches:    16 -    31] train loss: 0.069\n",
      "[epoch: 3, batches:    32 -    47] train loss: 0.069\n",
      "[epoch: 3, batches:    48 -    63] train loss: 0.070\n",
      "[epoch: 3, batches:    64 -    79] train loss: 0.075\n",
      "[epoch: 3, batches:    80 -    95] train loss: 0.070\n",
      "[epoch: 3, batches:    96 -   111] train loss: 0.069\n",
      "[epoch: 3, batches:   112 -   127] train loss: 0.066\n",
      "[epoch: 3, batches:   128 -   143] train loss: 0.066\n",
      "[epoch: 3, batches:   144 -   159] train loss: 0.068\n",
      "[epoch: 3, batches:   160 -   175] train loss: 0.071\n",
      "[epoch: 3, batches:   176 -   191] train loss: 0.061\n",
      "[epoch: 3, batches:   192 -   207] train loss: 0.062\n",
      "[epoch: 3, batches:   208 -   223] train loss: 0.066\n",
      "[epoch: 3, batches:   224 -   239] train loss: 0.063\n",
      "[epoch: 3, batches:   240 -   255] train loss: 0.061\n",
      "[epoch: 3, batches:   256 -   271] train loss: 0.062\n",
      "[epoch: 3, batches:   272 -   287] train loss: 0.065\n",
      "[epoch: 3, batches:   288 -   303] train loss: 0.063\n",
      "[epoch: 3, batches:   304 -   319] train loss: 0.063\n",
      "Training in epoch 3 finished. Train loss: 0.06281618191860616]\n",
      "[Validation in epoch 3 finished. Validation loss: 0.135]\n",
      "  Epoch: 4\n",
      "[epoch: 4, batches:     0 -    15] train loss: 0.060\n",
      "[epoch: 4, batches:    16 -    31] train loss: 0.059\n",
      "[epoch: 4, batches:    32 -    47] train loss: 0.058\n",
      "[epoch: 4, batches:    48 -    63] train loss: 0.058\n",
      "[epoch: 4, batches:    64 -    79] train loss: 0.059\n",
      "[epoch: 4, batches:    80 -    95] train loss: 0.057\n",
      "[epoch: 4, batches:    96 -   111] train loss: 0.060\n",
      "[epoch: 4, batches:   112 -   127] train loss: 0.061\n",
      "[epoch: 4, batches:   128 -   143] train loss: 0.057\n",
      "[epoch: 4, batches:   144 -   159] train loss: 0.054\n",
      "[epoch: 4, batches:   160 -   175] train loss: 0.057\n",
      "[epoch: 4, batches:   176 -   191] train loss: 0.057\n",
      "[epoch: 4, batches:   192 -   207] train loss: 0.057\n",
      "[epoch: 4, batches:   208 -   223] train loss: 0.061\n",
      "[epoch: 4, batches:   224 -   239] train loss: 0.063\n",
      "[epoch: 4, batches:   240 -   255] train loss: 0.060\n",
      "[epoch: 4, batches:   256 -   271] train loss: 0.059\n",
      "[epoch: 4, batches:   272 -   287] train loss: 0.051\n",
      "[epoch: 4, batches:   288 -   303] train loss: 0.058\n",
      "[epoch: 4, batches:   304 -   319] train loss: 0.057\n",
      "Training in epoch 4 finished. Train loss: 0.05741288885474205]\n",
      "[Validation in epoch 4 finished. Validation loss: 0.141]\n",
      "===== Training basic_unet_test for axis Y =====\n",
      "  Epoch: 0\n",
      "[epoch: 0, batches:     0 -    15] train loss: 1.137\n",
      "[epoch: 0, batches:    16 -    31] train loss: 0.279\n",
      "[epoch: 0, batches:    32 -    47] train loss: 0.201\n",
      "[epoch: 0, batches:    48 -    63] train loss: 0.177\n",
      "[epoch: 0, batches:    64 -    79] train loss: 0.176\n",
      "[epoch: 0, batches:    80 -    95] train loss: 0.175\n",
      "[epoch: 0, batches:    96 -   111] train loss: 0.166\n",
      "[epoch: 0, batches:   112 -   127] train loss: 0.149\n",
      "[epoch: 0, batches:   128 -   143] train loss: 0.151\n",
      "[epoch: 0, batches:   144 -   159] train loss: 0.136\n",
      "[epoch: 0, batches:   160 -   175] train loss: 0.135\n",
      "[epoch: 0, batches:   176 -   191] train loss: 0.126\n",
      "[epoch: 0, batches:   192 -   207] train loss: 0.126\n",
      "[epoch: 0, batches:   208 -   223] train loss: 0.124\n",
      "[epoch: 0, batches:   224 -   239] train loss: 0.125\n",
      "[epoch: 0, batches:   240 -   255] train loss: 0.122\n",
      "[epoch: 0, batches:   256 -   271] train loss: 0.115\n",
      "[epoch: 0, batches:   272 -   287] train loss: 0.109\n",
      "[epoch: 0, batches:   288 -   303] train loss: 0.106\n",
      "[epoch: 0, batches:   304 -   319] train loss: 0.102\n",
      "[epoch: 0, batches:   320 -   335] train loss: 0.108\n",
      "[epoch: 0, batches:   336 -   351] train loss: 0.087\n",
      "[epoch: 0, batches:   352 -   367] train loss: 0.106\n",
      "[epoch: 0, batches:   368 -   383] train loss: 0.103\n",
      "Training in epoch 0 finished. Train loss: 0.10266538104042411]\n",
      "[Validation in epoch 0 finished. Validation loss: 0.122]\n",
      "  Epoch: 1\n",
      "[epoch: 1, batches:     0 -    15] train loss: 0.098\n",
      "[epoch: 1, batches:    16 -    31] train loss: 0.090\n",
      "[epoch: 1, batches:    32 -    47] train loss: 0.094\n",
      "[epoch: 1, batches:    48 -    63] train loss: 0.091\n",
      "[epoch: 1, batches:    64 -    79] train loss: 0.093\n",
      "[epoch: 1, batches:    80 -    95] train loss: 0.078\n",
      "[epoch: 1, batches:    96 -   111] train loss: 0.085\n",
      "[epoch: 1, batches:   112 -   127] train loss: 0.085\n",
      "[epoch: 1, batches:   128 -   143] train loss: 0.082\n",
      "[epoch: 1, batches:   144 -   159] train loss: 0.084\n",
      "[epoch: 1, batches:   160 -   175] train loss: 0.087\n",
      "[epoch: 1, batches:   176 -   191] train loss: 0.085\n",
      "[epoch: 1, batches:   192 -   207] train loss: 0.079\n",
      "[epoch: 1, batches:   208 -   223] train loss: 0.076\n",
      "[epoch: 1, batches:   224 -   239] train loss: 0.079\n",
      "[epoch: 1, batches:   240 -   255] train loss: 0.076\n",
      "[epoch: 1, batches:   256 -   271] train loss: 0.072\n",
      "[epoch: 1, batches:   272 -   287] train loss: 0.069\n",
      "[epoch: 1, batches:   288 -   303] train loss: 0.069\n",
      "[epoch: 1, batches:   304 -   319] train loss: 0.068\n",
      "[epoch: 1, batches:   320 -   335] train loss: 0.072\n",
      "[epoch: 1, batches:   336 -   351] train loss: 0.077\n",
      "[epoch: 1, batches:   352 -   367] train loss: 0.068\n",
      "[epoch: 1, batches:   368 -   383] train loss: 0.070\n",
      "Training in epoch 1 finished. Train loss: 0.06996635836549103]\n",
      "[Validation in epoch 1 finished. Validation loss: 0.111]\n",
      "  Epoch: 2\n",
      "[epoch: 2, batches:     0 -    15] train loss: 0.068\n",
      "[epoch: 2, batches:    16 -    31] train loss: 0.067\n",
      "[epoch: 2, batches:    32 -    47] train loss: 0.069\n",
      "[epoch: 2, batches:    48 -    63] train loss: 0.064\n",
      "[epoch: 2, batches:    64 -    79] train loss: 0.064\n",
      "[epoch: 2, batches:    80 -    95] train loss: 0.061\n",
      "[epoch: 2, batches:    96 -   111] train loss: 0.065\n",
      "[epoch: 2, batches:   112 -   127] train loss: 0.061\n",
      "[epoch: 2, batches:   128 -   143] train loss: 0.064\n",
      "[epoch: 2, batches:   144 -   159] train loss: 0.055\n",
      "[epoch: 2, batches:   160 -   175] train loss: 0.062\n",
      "[epoch: 2, batches:   176 -   191] train loss: 0.057\n",
      "[epoch: 2, batches:   192 -   207] train loss: 0.060\n",
      "[epoch: 2, batches:   208 -   223] train loss: 0.060\n",
      "[epoch: 2, batches:   224 -   239] train loss: 0.055\n",
      "[epoch: 2, batches:   240 -   255] train loss: 0.059\n",
      "[epoch: 2, batches:   256 -   271] train loss: 0.061\n",
      "[epoch: 2, batches:   272 -   287] train loss: 0.056\n",
      "[epoch: 2, batches:   288 -   303] train loss: 0.059\n",
      "[epoch: 2, batches:   304 -   319] train loss: 0.057\n",
      "[epoch: 2, batches:   320 -   335] train loss: 0.054\n",
      "[epoch: 2, batches:   336 -   351] train loss: 0.055\n",
      "[epoch: 2, batches:   352 -   367] train loss: 0.054\n",
      "[epoch: 2, batches:   368 -   383] train loss: 0.056\n",
      "Training in epoch 2 finished. Train loss: 0.05630475911311805]\n",
      "[Validation in epoch 2 finished. Validation loss: 0.104]\n",
      "  Epoch: 3\n",
      "[epoch: 3, batches:     0 -    15] train loss: 0.052\n",
      "[epoch: 3, batches:    16 -    31] train loss: 0.053\n",
      "[epoch: 3, batches:    32 -    47] train loss: 0.055\n",
      "[epoch: 3, batches:    48 -    63] train loss: 0.049\n",
      "[epoch: 3, batches:    64 -    79] train loss: 0.053\n",
      "[epoch: 3, batches:    80 -    95] train loss: 0.053\n",
      "[epoch: 3, batches:    96 -   111] train loss: 0.050\n",
      "[epoch: 3, batches:   112 -   127] train loss: 0.049\n",
      "[epoch: 3, batches:   128 -   143] train loss: 0.045\n",
      "[epoch: 3, batches:   144 -   159] train loss: 0.049\n",
      "[epoch: 3, batches:   160 -   175] train loss: 0.051\n",
      "[epoch: 3, batches:   176 -   191] train loss: 0.048\n",
      "[epoch: 3, batches:   192 -   207] train loss: 0.047\n",
      "[epoch: 3, batches:   208 -   223] train loss: 0.053\n",
      "[epoch: 3, batches:   224 -   239] train loss: 0.044\n",
      "[epoch: 3, batches:   240 -   255] train loss: 0.051\n",
      "[epoch: 3, batches:   256 -   271] train loss: 0.047\n",
      "[epoch: 3, batches:   272 -   287] train loss: 0.044\n",
      "[epoch: 3, batches:   288 -   303] train loss: 0.045\n",
      "[epoch: 3, batches:   304 -   319] train loss: 0.048\n",
      "[epoch: 3, batches:   320 -   335] train loss: 0.046\n",
      "[epoch: 3, batches:   336 -   351] train loss: 0.045\n",
      "[epoch: 3, batches:   352 -   367] train loss: 0.047\n",
      "[epoch: 3, batches:   368 -   383] train loss: 0.042\n",
      "Training in epoch 3 finished. Train loss: 0.041576133226044476]\n",
      "[Validation in epoch 3 finished. Validation loss: 0.109]\n",
      "  Epoch: 4\n",
      "[epoch: 4, batches:     0 -    15] train loss: 0.041\n",
      "[epoch: 4, batches:    16 -    31] train loss: 0.045\n",
      "[epoch: 4, batches:    32 -    47] train loss: 0.045\n",
      "[epoch: 4, batches:    48 -    63] train loss: 0.043\n",
      "[epoch: 4, batches:    64 -    79] train loss: 0.045\n",
      "[epoch: 4, batches:    80 -    95] train loss: 0.042\n",
      "[epoch: 4, batches:    96 -   111] train loss: 0.038\n",
      "[epoch: 4, batches:   112 -   127] train loss: 0.041\n",
      "[epoch: 4, batches:   128 -   143] train loss: 0.039\n",
      "[epoch: 4, batches:   144 -   159] train loss: 0.037\n",
      "[epoch: 4, batches:   160 -   175] train loss: 0.038\n",
      "[epoch: 4, batches:   176 -   191] train loss: 0.044\n",
      "[epoch: 4, batches:   192 -   207] train loss: 0.038\n",
      "[epoch: 4, batches:   208 -   223] train loss: 0.041\n",
      "[epoch: 4, batches:   224 -   239] train loss: 0.039\n",
      "[epoch: 4, batches:   240 -   255] train loss: 0.038\n",
      "[epoch: 4, batches:   256 -   271] train loss: 0.043\n",
      "[epoch: 4, batches:   272 -   287] train loss: 0.040\n",
      "[epoch: 4, batches:   288 -   303] train loss: 0.040\n",
      "[epoch: 4, batches:   304 -   319] train loss: 0.038\n",
      "[epoch: 4, batches:   320 -   335] train loss: 0.040\n",
      "[epoch: 4, batches:   336 -   351] train loss: 0.036\n",
      "[epoch: 4, batches:   352 -   367] train loss: 0.043\n",
      "[epoch: 4, batches:   368 -   383] train loss: 0.039\n",
      "Training in epoch 4 finished. Train loss: 0.03923864371608943]\n",
      "[Validation in epoch 4 finished. Validation loss: 0.119]\n",
      "===== Training basic_unet_test for axis Z =====\n",
      "  Epoch: 0\n",
      "[epoch: 0, batches:     0 -    15] train loss: 1.274\n",
      "[epoch: 0, batches:    16 -    31] train loss: 0.308\n",
      "[epoch: 0, batches:    32 -    47] train loss: 0.241\n",
      "[epoch: 0, batches:    48 -    63] train loss: 0.225\n",
      "[epoch: 0, batches:    64 -    79] train loss: 0.203\n",
      "[epoch: 0, batches:    80 -    95] train loss: 0.195\n",
      "[epoch: 0, batches:    96 -   111] train loss: 0.200\n",
      "[epoch: 0, batches:   112 -   127] train loss: 0.192\n",
      "[epoch: 0, batches:   128 -   143] train loss: 0.186\n",
      "[epoch: 0, batches:   144 -   159] train loss: 0.177\n",
      "[epoch: 0, batches:   160 -   175] train loss: 0.190\n",
      "[epoch: 0, batches:   176 -   191] train loss: 0.170\n",
      "[epoch: 0, batches:   192 -   207] train loss: 0.172\n",
      "[epoch: 0, batches:   208 -   223] train loss: 0.166\n",
      "[epoch: 0, batches:   224 -   239] train loss: 0.162\n",
      "[epoch: 0, batches:   240 -   255] train loss: 0.155\n",
      "[epoch: 0, batches:   256 -   271] train loss: 0.144\n",
      "[epoch: 0, batches:   272 -   287] train loss: 0.140\n",
      "[epoch: 0, batches:   288 -   303] train loss: 0.136\n",
      "[epoch: 0, batches:   304 -   319] train loss: 0.145\n",
      "[epoch: 0, batches:   320 -   335] train loss: 0.136\n",
      "Training in epoch 0 finished. Train loss: 0.13606025837361813]\n",
      "[Validation in epoch 0 finished. Validation loss: 0.200]\n",
      "  Epoch: 1\n",
      "[epoch: 1, batches:     0 -    15] train loss: 0.133\n",
      "[epoch: 1, batches:    16 -    31] train loss: 0.140\n",
      "[epoch: 1, batches:    32 -    47] train loss: 0.123\n",
      "[epoch: 1, batches:    48 -    63] train loss: 0.109\n",
      "[epoch: 1, batches:    64 -    79] train loss: 0.129\n",
      "[epoch: 1, batches:    80 -    95] train loss: 0.121\n",
      "[epoch: 1, batches:    96 -   111] train loss: 0.117\n",
      "[epoch: 1, batches:   112 -   127] train loss: 0.124\n",
      "[epoch: 1, batches:   128 -   143] train loss: 0.096\n",
      "[epoch: 1, batches:   144 -   159] train loss: 0.105\n",
      "[epoch: 1, batches:   160 -   175] train loss: 0.099\n",
      "[epoch: 1, batches:   176 -   191] train loss: 0.099\n",
      "[epoch: 1, batches:   192 -   207] train loss: 0.093\n",
      "[epoch: 1, batches:   208 -   223] train loss: 0.101\n",
      "[epoch: 1, batches:   224 -   239] train loss: 0.110\n",
      "[epoch: 1, batches:   240 -   255] train loss: 0.109\n",
      "[epoch: 1, batches:   256 -   271] train loss: 0.105\n",
      "[epoch: 1, batches:   272 -   287] train loss: 0.098\n",
      "[epoch: 1, batches:   288 -   303] train loss: 0.091\n",
      "[epoch: 1, batches:   304 -   319] train loss: 0.101\n",
      "[epoch: 1, batches:   320 -   335] train loss: 0.085\n",
      "Training in epoch 1 finished. Train loss: 0.08488615811802447]\n",
      "[Validation in epoch 1 finished. Validation loss: 0.134]\n",
      "  Epoch: 2\n",
      "[epoch: 2, batches:     0 -    15] train loss: 0.083\n",
      "[epoch: 2, batches:    16 -    31] train loss: 0.081\n",
      "[epoch: 2, batches:    32 -    47] train loss: 0.085\n",
      "[epoch: 2, batches:    48 -    63] train loss: 0.094\n",
      "[epoch: 2, batches:    64 -    79] train loss: 0.085\n",
      "[epoch: 2, batches:    80 -    95] train loss: 0.088\n",
      "[epoch: 2, batches:    96 -   111] train loss: 0.077\n",
      "[epoch: 2, batches:   112 -   127] train loss: 0.087\n",
      "[epoch: 2, batches:   128 -   143] train loss: 0.087\n",
      "[epoch: 2, batches:   144 -   159] train loss: 0.090\n",
      "[epoch: 2, batches:   160 -   175] train loss: 0.077\n",
      "[epoch: 2, batches:   176 -   191] train loss: 0.081\n",
      "[epoch: 2, batches:   192 -   207] train loss: 0.084\n",
      "[epoch: 2, batches:   208 -   223] train loss: 0.077\n",
      "[epoch: 2, batches:   224 -   239] train loss: 0.094\n",
      "[epoch: 2, batches:   240 -   255] train loss: 0.083\n",
      "[epoch: 2, batches:   256 -   271] train loss: 0.077\n",
      "[epoch: 2, batches:   272 -   287] train loss: 0.075\n",
      "[epoch: 2, batches:   288 -   303] train loss: 0.084\n",
      "[epoch: 2, batches:   304 -   319] train loss: 0.077\n",
      "[epoch: 2, batches:   320 -   335] train loss: 0.085\n",
      "Training in epoch 2 finished. Train loss: 0.08460836764425039]\n",
      "[Validation in epoch 2 finished. Validation loss: 0.123]\n",
      "  Epoch: 3\n",
      "[epoch: 3, batches:     0 -    15] train loss: 0.077\n",
      "[epoch: 3, batches:    16 -    31] train loss: 0.068\n",
      "[epoch: 3, batches:    32 -    47] train loss: 0.072\n",
      "[epoch: 3, batches:    48 -    63] train loss: 0.069\n",
      "[epoch: 3, batches:    64 -    79] train loss: 0.074\n",
      "[epoch: 3, batches:    80 -    95] train loss: 0.071\n",
      "[epoch: 3, batches:    96 -   111] train loss: 0.072\n",
      "[epoch: 3, batches:   112 -   127] train loss: 0.071\n",
      "[epoch: 3, batches:   128 -   143] train loss: 0.078\n",
      "[epoch: 3, batches:   144 -   159] train loss: 0.065\n",
      "[epoch: 3, batches:   160 -   175] train loss: 0.067\n",
      "[epoch: 3, batches:   176 -   191] train loss: 0.069\n",
      "[epoch: 3, batches:   192 -   207] train loss: 0.070\n",
      "[epoch: 3, batches:   208 -   223] train loss: 0.074\n",
      "[epoch: 3, batches:   224 -   239] train loss: 0.064\n",
      "[epoch: 3, batches:   240 -   255] train loss: 0.067\n",
      "[epoch: 3, batches:   256 -   271] train loss: 0.068\n",
      "[epoch: 3, batches:   272 -   287] train loss: 0.064\n",
      "[epoch: 3, batches:   288 -   303] train loss: 0.068\n",
      "[epoch: 3, batches:   304 -   319] train loss: 0.071\n",
      "[epoch: 3, batches:   320 -   335] train loss: 0.064\n",
      "Training in epoch 3 finished. Train loss: 0.06377131550107151]\n",
      "[Validation in epoch 3 finished. Validation loss: 0.121]\n",
      "  Epoch: 4\n",
      "[epoch: 4, batches:     0 -    15] train loss: 0.065\n",
      "[epoch: 4, batches:    16 -    31] train loss: 0.062\n",
      "[epoch: 4, batches:    32 -    47] train loss: 0.062\n",
      "[epoch: 4, batches:    48 -    63] train loss: 0.058\n",
      "[epoch: 4, batches:    64 -    79] train loss: 0.064\n",
      "[epoch: 4, batches:    80 -    95] train loss: 0.061\n",
      "[epoch: 4, batches:    96 -   111] train loss: 0.059\n",
      "[epoch: 4, batches:   112 -   127] train loss: 0.060\n",
      "[epoch: 4, batches:   128 -   143] train loss: 0.061\n",
      "[epoch: 4, batches:   144 -   159] train loss: 0.056\n",
      "[epoch: 4, batches:   160 -   175] train loss: 0.063\n",
      "[epoch: 4, batches:   176 -   191] train loss: 0.066\n",
      "[epoch: 4, batches:   192 -   207] train loss: 0.065\n",
      "[epoch: 4, batches:   208 -   223] train loss: 0.066\n",
      "[epoch: 4, batches:   224 -   239] train loss: 0.064\n",
      "[epoch: 4, batches:   240 -   255] train loss: 0.056\n",
      "[epoch: 4, batches:   256 -   271] train loss: 0.060\n",
      "[epoch: 4, batches:   272 -   287] train loss: 0.055\n",
      "[epoch: 4, batches:   288 -   303] train loss: 0.061\n",
      "[epoch: 4, batches:   304 -   319] train loss: 0.055\n",
      "[epoch: 4, batches:   320 -   335] train loss: 0.054\n",
      "Training in epoch 4 finished. Train loss: 0.054487997433170676]\n",
      "[Validation in epoch 4 finished. Validation loss: 0.112]\n"
     ]
    }
   ],
   "source": [
    "# config params\n",
    "load_model = False\n",
    "model_name = 'basic_unet_test'\n",
    "axes = ['X', 'Y', 'Z']\n",
    "\n",
    "for axis in axes:\n",
    "    print(f'===== Training {model_name} for axis {axis} =====')\n",
    "\n",
    "    # networks params\n",
    "    network = BasicUNET(in_channels=1, classes=8)\n",
    "    optimizer_name = \"adam\"\n",
    "    learning_rate = 0.0005\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    batch_size = 16\n",
    "    epochs = 5\n",
    "    img_height = 32\n",
    "    img_width = 32\n",
    "\n",
    "    # data\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_height, img_width), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "    ])\n",
    "    train_loader = load_BrainTissue_data(configs.DATA_2D_PATH, TRAIN_IDX_START, TRAIN_IDX_STOP, axis, transform, batch_size)\n",
    "    val_loader = load_BrainTissue_data(configs.DATA_2D_PATH, VAL_IDX_START, VAL_IDX_STOP, axis, transform, batch_size)\n",
    "\n",
    "    # save model params\n",
    "    save_params(\n",
    "        model_name=model_name,\n",
    "        axis=axis,\n",
    "        optimizer_name=optimizer_name,\n",
    "        loss_fn=str(loss_fn),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        img_height=img_height,\n",
    "        img_width=img_width,\n",
    "        parms_path=get_parms_path(model_name, axis)\n",
    "    )\n",
    "\n",
    "    # train network\n",
    "    train_network(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        network=network, \n",
    "        optimizer_name=optimizer_name, \n",
    "        learning_rate=learning_rate, \n",
    "        loss_fn=loss_fn, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        load_model=load_model,\n",
    "        model_path=get_model_path(model_name, axis),  \n",
    "        loss_path=get_loss_path(model_name, axis),\n",
    "        device=DEVICE\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 x Basic Unet 64x64 + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training basic_unet_64_local for axis Y =====\n",
      "  Epoch: 0\n",
      "[epoch: 0, batches:     0 -    15] train loss: 0.960\n",
      "[epoch: 0, batches:    16 -    31] train loss: 0.298\n",
      "[epoch: 0, batches:    32 -    47] train loss: 0.246\n",
      "[epoch: 0, batches:    48 -    63] train loss: 0.230\n",
      "[epoch: 0, batches:    64 -    79] train loss: 0.224\n",
      "[epoch: 0, batches:    80 -    95] train loss: 0.228\n",
      "[epoch: 0, batches:    96 -   111] train loss: 0.206\n",
      "[epoch: 0, batches:   112 -   127] train loss: 0.191\n",
      "[epoch: 0, batches:   128 -   143] train loss: 0.188\n",
      "[epoch: 0, batches:   144 -   159] train loss: 0.174\n",
      "[epoch: 0, batches:   160 -   175] train loss: 0.176\n",
      "[epoch: 0, batches:   176 -   191] train loss: 0.179\n",
      "Training in epoch 0 finished. Train loss: 0.1792494971305132]\n",
      "[Validation in epoch 0 finished. Validation loss: 0.166]\n",
      "  Epoch: 1\n",
      "[epoch: 1, batches:     0 -    15] train loss: 0.168\n",
      "[epoch: 1, batches:    16 -    31] train loss: 0.171\n",
      "[epoch: 1, batches:    32 -    47] train loss: 0.156\n",
      "[epoch: 1, batches:    48 -    63] train loss: 0.142\n",
      "[epoch: 1, batches:    64 -    79] train loss: 0.153\n",
      "[epoch: 1, batches:    80 -    95] train loss: 0.152\n",
      "[epoch: 1, batches:    96 -   111] train loss: 0.148\n",
      "[epoch: 1, batches:   112 -   127] train loss: 0.152\n",
      "[epoch: 1, batches:   128 -   143] train loss: 0.132\n",
      "[epoch: 1, batches:   144 -   159] train loss: 0.141\n",
      "[epoch: 1, batches:   160 -   175] train loss: 0.135\n",
      "[epoch: 1, batches:   176 -   191] train loss: 0.138\n",
      "Training in epoch 1 finished. Train loss: 0.13766556093469262]\n",
      "[Validation in epoch 1 finished. Validation loss: 0.122]\n",
      "  Epoch: 2\n",
      "[epoch: 2, batches:     0 -    15] train loss: 0.123\n",
      "[epoch: 2, batches:    16 -    31] train loss: 0.138\n",
      "[epoch: 2, batches:    32 -    47] train loss: 0.123\n",
      "[epoch: 2, batches:    48 -    63] train loss: 0.122\n",
      "[epoch: 2, batches:    64 -    79] train loss: 0.118\n",
      "[epoch: 2, batches:    80 -    95] train loss: 0.124\n",
      "[epoch: 2, batches:    96 -   111] train loss: 0.122\n",
      "[epoch: 2, batches:   112 -   127] train loss: 0.127\n",
      "[epoch: 2, batches:   128 -   143] train loss: 0.121\n",
      "[epoch: 2, batches:   144 -   159] train loss: 0.113\n",
      "[epoch: 2, batches:   160 -   175] train loss: 0.103\n",
      "[epoch: 2, batches:   176 -   191] train loss: 0.104\n",
      "Training in epoch 2 finished. Train loss: 0.10432585701346397]\n",
      "[Validation in epoch 2 finished. Validation loss: 0.098]\n",
      "  Epoch: 3\n",
      "[epoch: 3, batches:     0 -    15] train loss: 0.107\n",
      "[epoch: 3, batches:    16 -    31] train loss: 0.110\n",
      "[epoch: 3, batches:    32 -    47] train loss: 0.111\n",
      "[epoch: 3, batches:    48 -    63] train loss: 0.102\n",
      "[epoch: 3, batches:    64 -    79] train loss: 0.102\n",
      "[epoch: 3, batches:    80 -    95] train loss: 0.099\n",
      "[epoch: 3, batches:    96 -   111] train loss: 0.100\n",
      "[epoch: 3, batches:   112 -   127] train loss: 0.102\n",
      "[epoch: 3, batches:   128 -   143] train loss: 0.099\n",
      "[epoch: 3, batches:   144 -   159] train loss: 0.096\n",
      "[epoch: 3, batches:   160 -   175] train loss: 0.099\n",
      "[epoch: 3, batches:   176 -   191] train loss: 0.100\n",
      "Training in epoch 3 finished. Train loss: 0.10001500509679317]\n",
      "[Validation in epoch 3 finished. Validation loss: 0.088]\n",
      "  Epoch: 4\n",
      "[epoch: 4, batches:     0 -    15] train loss: 0.106\n",
      "[epoch: 4, batches:    16 -    31] train loss: 0.096\n",
      "[epoch: 4, batches:    32 -    47] train loss: 0.092\n",
      "[epoch: 4, batches:    48 -    63] train loss: 0.101\n",
      "[epoch: 4, batches:    64 -    79] train loss: 0.100\n",
      "[epoch: 4, batches:    80 -    95] train loss: 0.091\n",
      "[epoch: 4, batches:    96 -   111] train loss: 0.098\n",
      "[epoch: 4, batches:   112 -   127] train loss: 0.098\n",
      "[epoch: 4, batches:   128 -   143] train loss: 0.094\n",
      "[epoch: 4, batches:   144 -   159] train loss: 0.088\n",
      "[epoch: 4, batches:   160 -   175] train loss: 0.090\n",
      "[epoch: 4, batches:   176 -   191] train loss: 0.094\n",
      "Training in epoch 4 finished. Train loss: 0.09361929493024945]\n",
      "[Validation in epoch 4 finished. Validation loss: 0.085]\n",
      "  Epoch: 5\n",
      "[epoch: 5, batches:     0 -    15] train loss: 0.089\n",
      "[epoch: 5, batches:    16 -    31] train loss: 0.088\n",
      "[epoch: 5, batches:    32 -    47] train loss: 0.093\n",
      "[epoch: 5, batches:    48 -    63] train loss: 0.086\n",
      "[epoch: 5, batches:    64 -    79] train loss: 0.090\n",
      "[epoch: 5, batches:    80 -    95] train loss: 0.088\n",
      "[epoch: 5, batches:    96 -   111] train loss: 0.091\n",
      "[epoch: 5, batches:   112 -   127] train loss: 0.100\n",
      "[epoch: 5, batches:   128 -   143] train loss: 0.088\n",
      "[epoch: 5, batches:   144 -   159] train loss: 0.088\n",
      "[epoch: 5, batches:   160 -   175] train loss: 0.085\n",
      "[epoch: 5, batches:   176 -   191] train loss: 0.082\n",
      "Training in epoch 5 finished. Train loss: 0.0821237163618207]\n",
      "[Validation in epoch 5 finished. Validation loss: 0.086]\n",
      "  Epoch: 6\n",
      "[epoch: 6, batches:     0 -    15] train loss: 0.089\n",
      "[epoch: 6, batches:    16 -    31] train loss: 0.084\n",
      "[epoch: 6, batches:    32 -    47] train loss: 0.085\n",
      "[epoch: 6, batches:    48 -    63] train loss: 0.087\n",
      "[epoch: 6, batches:    64 -    79] train loss: 0.084\n",
      "[epoch: 6, batches:    80 -    95] train loss: 0.082\n",
      "[epoch: 6, batches:    96 -   111] train loss: 0.083\n",
      "[epoch: 6, batches:   112 -   127] train loss: 0.085\n",
      "[epoch: 6, batches:   128 -   143] train loss: 0.084\n",
      "[epoch: 6, batches:   144 -   159] train loss: 0.088\n",
      "[epoch: 6, batches:   160 -   175] train loss: 0.085\n",
      "[epoch: 6, batches:   176 -   191] train loss: 0.085\n",
      "Training in epoch 6 finished. Train loss: 0.08525617979466915]\n",
      "[Validation in epoch 6 finished. Validation loss: 0.077]\n",
      "  Epoch: 7\n",
      "[epoch: 7, batches:     0 -    15] train loss: 0.085\n",
      "[epoch: 7, batches:    16 -    31] train loss: 0.078\n",
      "[epoch: 7, batches:    32 -    47] train loss: 0.084\n",
      "[epoch: 7, batches:    48 -    63] train loss: 0.080\n",
      "[epoch: 7, batches:    64 -    79] train loss: 0.083\n",
      "[epoch: 7, batches:    80 -    95] train loss: 0.082\n",
      "[epoch: 7, batches:    96 -   111] train loss: 0.084\n",
      "[epoch: 7, batches:   112 -   127] train loss: 0.090\n",
      "[epoch: 7, batches:   128 -   143] train loss: 0.083\n",
      "[epoch: 7, batches:   144 -   159] train loss: 0.085\n",
      "[epoch: 7, batches:   160 -   175] train loss: 0.084\n",
      "[epoch: 7, batches:   176 -   191] train loss: 0.080\n",
      "Training in epoch 7 finished. Train loss: 0.08000817988067865]\n",
      "[Validation in epoch 7 finished. Validation loss: 0.083]\n",
      "  Epoch: 8\n",
      "[epoch: 8, batches:     0 -    15] train loss: 0.083\n",
      "[epoch: 8, batches:    16 -    31] train loss: 0.078\n",
      "[epoch: 8, batches:    32 -    47] train loss: 0.081\n",
      "[epoch: 8, batches:    48 -    63] train loss: 0.078\n",
      "[epoch: 8, batches:    64 -    79] train loss: 0.075\n",
      "[epoch: 8, batches:    80 -    95] train loss: 0.078\n",
      "[epoch: 8, batches:    96 -   111] train loss: 0.083\n",
      "[epoch: 8, batches:   112 -   127] train loss: 0.080\n",
      "[epoch: 8, batches:   128 -   143] train loss: 0.080\n",
      "[epoch: 8, batches:   144 -   159] train loss: 0.081\n",
      "[epoch: 8, batches:   160 -   175] train loss: 0.081\n",
      "[epoch: 8, batches:   176 -   191] train loss: 0.082\n",
      "Training in epoch 8 finished. Train loss: 0.08155825454741716]\n",
      "[Validation in epoch 8 finished. Validation loss: 0.072]\n",
      "  Epoch: 9\n",
      "[epoch: 9, batches:     0 -    15] train loss: 0.081\n",
      "[epoch: 9, batches:    16 -    31] train loss: 0.082\n",
      "[epoch: 9, batches:    32 -    47] train loss: 0.078\n",
      "[epoch: 9, batches:    48 -    63] train loss: 0.076\n",
      "[epoch: 9, batches:    64 -    79] train loss: 0.084\n",
      "[epoch: 9, batches:    80 -    95] train loss: 0.076\n",
      "[epoch: 9, batches:    96 -   111] train loss: 0.077\n",
      "[epoch: 9, batches:   112 -   127] train loss: 0.074\n",
      "[epoch: 9, batches:   128 -   143] train loss: 0.079\n",
      "[epoch: 9, batches:   144 -   159] train loss: 0.081\n",
      "[epoch: 9, batches:   160 -   175] train loss: 0.075\n",
      "[epoch: 9, batches:   176 -   191] train loss: 0.079\n",
      "Training in epoch 9 finished. Train loss: 0.0793352690525353]\n",
      "[Validation in epoch 9 finished. Validation loss: 0.078]\n",
      "===== Training basic_unet_64_local for axis Z =====\n",
      "  Epoch: 0\n",
      "[epoch: 0, batches:     0 -    15] train loss: 1.212\n",
      "[epoch: 0, batches:    16 -    31] train loss: 0.350\n",
      "[epoch: 0, batches:    32 -    47] train loss: 0.303\n",
      "[epoch: 0, batches:    48 -    63] train loss: 0.261\n",
      "[epoch: 0, batches:    64 -    79] train loss: 0.246\n",
      "[epoch: 0, batches:    80 -    95] train loss: 0.233\n",
      "[epoch: 0, batches:    96 -   111] train loss: 0.197\n",
      "[epoch: 0, batches:   112 -   127] train loss: 0.213\n",
      "[epoch: 0, batches:   128 -   143] train loss: 0.216\n",
      "[epoch: 0, batches:   144 -   159] train loss: 0.236\n",
      "Training in epoch 0 finished. Train loss: 0.23623439762741327]\n",
      "[Validation in epoch 0 finished. Validation loss: 0.195]\n",
      "  Epoch: 1\n",
      "[epoch: 1, batches:     0 -    15] train loss: 0.191\n",
      "[epoch: 1, batches:    16 -    31] train loss: 0.192\n",
      "[epoch: 1, batches:    32 -    47] train loss: 0.193\n",
      "[epoch: 1, batches:    48 -    63] train loss: 0.182\n",
      "[epoch: 1, batches:    64 -    79] train loss: 0.189\n",
      "[epoch: 1, batches:    80 -    95] train loss: 0.177\n",
      "[epoch: 1, batches:    96 -   111] train loss: 0.184\n",
      "[epoch: 1, batches:   112 -   127] train loss: 0.165\n",
      "[epoch: 1, batches:   128 -   143] train loss: 0.168\n",
      "[epoch: 1, batches:   144 -   159] train loss: 0.180\n",
      "Training in epoch 1 finished. Train loss: 0.18031888362020254]\n",
      "[Validation in epoch 1 finished. Validation loss: 0.179]\n",
      "  Epoch: 2\n",
      "[epoch: 2, batches:     0 -    15] train loss: 0.177\n",
      "[epoch: 2, batches:    16 -    31] train loss: 0.171\n",
      "[epoch: 2, batches:    32 -    47] train loss: 0.163\n",
      "[epoch: 2, batches:    48 -    63] train loss: 0.167\n",
      "[epoch: 2, batches:    64 -    79] train loss: 0.156\n",
      "[epoch: 2, batches:    80 -    95] train loss: 0.156\n",
      "[epoch: 2, batches:    96 -   111] train loss: 0.155\n",
      "[epoch: 2, batches:   112 -   127] train loss: 0.148\n",
      "[epoch: 2, batches:   128 -   143] train loss: 0.147\n",
      "[epoch: 2, batches:   144 -   159] train loss: 0.149\n",
      "Training in epoch 2 finished. Train loss: 0.14920624578371644]\n",
      "[Validation in epoch 2 finished. Validation loss: 0.130]\n",
      "  Epoch: 3\n",
      "[epoch: 3, batches:     0 -    15] train loss: 0.141\n",
      "[epoch: 3, batches:    16 -    31] train loss: 0.136\n",
      "[epoch: 3, batches:    32 -    47] train loss: 0.138\n",
      "[epoch: 3, batches:    48 -    63] train loss: 0.138\n",
      "[epoch: 3, batches:    64 -    79] train loss: 0.143\n",
      "[epoch: 3, batches:    80 -    95] train loss: 0.132\n",
      "[epoch: 3, batches:    96 -   111] train loss: 0.147\n",
      "[epoch: 3, batches:   112 -   127] train loss: 0.144\n",
      "[epoch: 3, batches:   128 -   143] train loss: 0.126\n",
      "[epoch: 3, batches:   144 -   159] train loss: 0.122\n",
      "Training in epoch 3 finished. Train loss: 0.12249575136229396]\n",
      "[Validation in epoch 3 finished. Validation loss: 0.114]\n",
      "  Epoch: 4\n",
      "[epoch: 4, batches:     0 -    15] train loss: 0.127\n",
      "[epoch: 4, batches:    16 -    31] train loss: 0.125\n",
      "[epoch: 4, batches:    32 -    47] train loss: 0.134\n",
      "[epoch: 4, batches:    48 -    63] train loss: 0.125\n",
      "[epoch: 4, batches:    64 -    79] train loss: 0.125\n",
      "[epoch: 4, batches:    80 -    95] train loss: 0.120\n",
      "[epoch: 4, batches:    96 -   111] train loss: 0.122\n",
      "[epoch: 4, batches:   112 -   127] train loss: 0.114\n",
      "[epoch: 4, batches:   128 -   143] train loss: 0.110\n",
      "[epoch: 4, batches:   144 -   159] train loss: 0.124\n",
      "Training in epoch 4 finished. Train loss: 0.12411416508257389]\n",
      "[Validation in epoch 4 finished. Validation loss: 0.109]\n",
      "  Epoch: 5\n",
      "[epoch: 5, batches:     0 -    15] train loss: 0.123\n",
      "[epoch: 5, batches:    16 -    31] train loss: 0.112\n",
      "[epoch: 5, batches:    32 -    47] train loss: 0.115\n",
      "[epoch: 5, batches:    48 -    63] train loss: 0.114\n",
      "[epoch: 5, batches:    64 -    79] train loss: 0.108\n",
      "[epoch: 5, batches:    80 -    95] train loss: 0.112\n",
      "[epoch: 5, batches:    96 -   111] train loss: 0.105\n",
      "[epoch: 5, batches:   112 -   127] train loss: 0.128\n",
      "[epoch: 5, batches:   128 -   143] train loss: 0.108\n",
      "[epoch: 5, batches:   144 -   159] train loss: 0.107\n",
      "Training in epoch 5 finished. Train loss: 0.10738921165466309]\n",
      "[Validation in epoch 5 finished. Validation loss: 0.119]\n",
      "  Epoch: 6\n",
      "[epoch: 6, batches:     0 -    15] train loss: 0.108\n",
      "[epoch: 6, batches:    16 -    31] train loss: 0.108\n",
      "[epoch: 6, batches:    32 -    47] train loss: 0.106\n",
      "[epoch: 6, batches:    48 -    63] train loss: 0.104\n",
      "[epoch: 6, batches:    64 -    79] train loss: 0.115\n",
      "[epoch: 6, batches:    80 -    95] train loss: 0.123\n",
      "[epoch: 6, batches:    96 -   111] train loss: 0.129\n",
      "[epoch: 6, batches:   112 -   127] train loss: 0.123\n",
      "[epoch: 6, batches:   128 -   143] train loss: 0.109\n",
      "[epoch: 6, batches:   144 -   159] train loss: 0.110\n",
      "Training in epoch 6 finished. Train loss: 0.10951393051072955]\n",
      "[Validation in epoch 6 finished. Validation loss: 0.110]\n",
      "  Epoch: 7\n",
      "[epoch: 7, batches:     0 -    15] train loss: 0.108\n",
      "[epoch: 7, batches:    16 -    31] train loss: 0.113\n",
      "[epoch: 7, batches:    32 -    47] train loss: 0.105\n",
      "[epoch: 7, batches:    48 -    63] train loss: 0.099\n",
      "[epoch: 7, batches:    64 -    79] train loss: 0.094\n",
      "[epoch: 7, batches:    80 -    95] train loss: 0.102\n",
      "[epoch: 7, batches:    96 -   111] train loss: 0.094\n",
      "[epoch: 7, batches:   112 -   127] train loss: 0.100\n",
      "[epoch: 7, batches:   128 -   143] train loss: 0.106\n",
      "[epoch: 7, batches:   144 -   159] train loss: 0.102\n",
      "Training in epoch 7 finished. Train loss: 0.10240360163152218]\n",
      "[Validation in epoch 7 finished. Validation loss: 0.098]\n",
      "  Epoch: 8\n",
      "[epoch: 8, batches:     0 -    15] train loss: 0.099\n",
      "[epoch: 8, batches:    16 -    31] train loss: 0.091\n",
      "[epoch: 8, batches:    32 -    47] train loss: 0.100\n",
      "[epoch: 8, batches:    48 -    63] train loss: 0.095\n",
      "[epoch: 8, batches:    64 -    79] train loss: 0.107\n",
      "[epoch: 8, batches:    80 -    95] train loss: 0.101\n",
      "[epoch: 8, batches:    96 -   111] train loss: 0.100\n",
      "[epoch: 8, batches:   112 -   127] train loss: 0.095\n",
      "[epoch: 8, batches:   128 -   143] train loss: 0.100\n",
      "[epoch: 8, batches:   144 -   159] train loss: 0.092\n",
      "Training in epoch 8 finished. Train loss: 0.09188422746956348]\n",
      "[Validation in epoch 8 finished. Validation loss: 0.094]\n",
      "  Epoch: 9\n",
      "[epoch: 9, batches:     0 -    15] train loss: 0.093\n",
      "[epoch: 9, batches:    16 -    31] train loss: 0.095\n",
      "[epoch: 9, batches:    32 -    47] train loss: 0.099\n",
      "[epoch: 9, batches:    48 -    63] train loss: 0.104\n",
      "[epoch: 9, batches:    64 -    79] train loss: 0.089\n",
      "[epoch: 9, batches:    80 -    95] train loss: 0.101\n",
      "[epoch: 9, batches:    96 -   111] train loss: 0.091\n",
      "[epoch: 9, batches:   112 -   127] train loss: 0.093\n",
      "[epoch: 9, batches:   128 -   143] train loss: 0.103\n",
      "[epoch: 9, batches:   144 -   159] train loss: 0.088\n",
      "Training in epoch 9 finished. Train loss: 0.0880377353169024]\n",
      "[Validation in epoch 9 finished. Validation loss: 0.097]\n"
     ]
    }
   ],
   "source": [
    "# config params\n",
    "load_model = False\n",
    "model_name = 'basic_unet_64_local'\n",
    "axes = ['X', 'Y', 'Z']\n",
    "\n",
    "for axis in axes:\n",
    "    print(f'===== Training {model_name} for axis {axis} =====')\n",
    "\n",
    "    # networks params\n",
    "    network = BasicUNET(in_channels=1, classes=8)\n",
    "    optimizer_name = \"adam\"\n",
    "    learning_rate = 0.0005\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    batch_size = 32\n",
    "    epochs = 10\n",
    "    img_height = 64\n",
    "    img_width = 64\n",
    "\n",
    "    # data\n",
    "    train_transform = transforms.Compose([\n",
    "        \n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=50),\n",
    "        transforms.RandomResizedCrop(size=(configs.IMG_ORYG_HEIGHT, configs.IMG_ORYG_WIDTH), scale=(0.6, 1.0)),\n",
    "        transforms.Resize((img_height, img_width), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((img_height, img_width), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    ])\n",
    "    train_loader = load_BrainTissue_data(configs.DATA_2D_PATH, TRAIN_IDX_START, TRAIN_IDX_STOP, axis, train_transform, batch_size)\n",
    "    val_loader = load_BrainTissue_data(configs.DATA_2D_PATH, VAL_IDX_START, VAL_IDX_STOP, axis, val_transform, batch_size)\n",
    "\n",
    "    # save model params\n",
    "    save_params(\n",
    "        model_name=model_name,\n",
    "        axis=axis,\n",
    "        optimizer_name=optimizer_name,\n",
    "        loss_fn=str(loss_fn),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        img_height=img_height,\n",
    "        img_width=img_width,\n",
    "        parms_path=get_parms_path(model_name, axis)\n",
    "    )\n",
    "\n",
    "    # train network\n",
    "    train_network(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        network=network, \n",
    "        optimizer_name=optimizer_name, \n",
    "        learning_rate=learning_rate, \n",
    "        loss_fn=loss_fn, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        load_model=load_model,\n",
    "        model_path=get_model_path(model_name, axis),  \n",
    "        loss_path=get_loss_path(model_name, axis),\n",
    "        device=DEVICE\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 x Basic Unet 128x128 + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training basic_unet_128_local for axis Z =====\n",
      "Model loaded from checkpoint\n",
      "  Epoch: 4\n",
      "[epoch: 4, batches:     0 -    15] train loss: 0.152\n",
      "[epoch: 4, batches:    16 -    31] train loss: 0.149\n",
      "[epoch: 4, batches:    32 -    47] train loss: 0.147\n",
      "[epoch: 4, batches:    48 -    63] train loss: 0.153\n",
      "[epoch: 4, batches:    64 -    79] train loss: 0.133\n",
      "[epoch: 4, batches:    80 -    95] train loss: 0.153\n",
      "[epoch: 4, batches:    96 -   111] train loss: 0.141\n",
      "[epoch: 4, batches:   112 -   127] train loss: 0.133\n",
      "[epoch: 4, batches:   128 -   143] train loss: 0.139\n",
      "[epoch: 4, batches:   144 -   159] train loss: 0.129\n",
      "Training in epoch 4 finished. Train loss: 0.12945549562573433]\n",
      "[Validation in epoch 4 finished. Validation loss: 0.117]\n",
      "  Epoch: 5\n",
      "[epoch: 5, batches:     0 -    15] train loss: 0.136\n",
      "[epoch: 5, batches:    16 -    31] train loss: 0.135\n",
      "[epoch: 5, batches:    32 -    47] train loss: 0.119\n",
      "[epoch: 5, batches:    48 -    63] train loss: 0.140\n",
      "[epoch: 5, batches:    64 -    79] train loss: 0.137\n",
      "[epoch: 5, batches:    80 -    95] train loss: 0.131\n",
      "[epoch: 5, batches:    96 -   111] train loss: 0.139\n",
      "[epoch: 5, batches:   112 -   127] train loss: 0.125\n",
      "[epoch: 5, batches:   128 -   143] train loss: 0.123\n",
      "[epoch: 5, batches:   144 -   159] train loss: 0.113\n",
      "Training in epoch 5 finished. Train loss: 0.11281397705897689]\n",
      "[Validation in epoch 5 finished. Validation loss: 0.103]\n",
      "  Epoch: 6\n",
      "[epoch: 6, batches:     0 -    15] train loss: 0.117\n",
      "[epoch: 6, batches:    16 -    31] train loss: 0.123\n",
      "[epoch: 6, batches:    32 -    47] train loss: 0.128\n",
      "[epoch: 6, batches:    48 -    63] train loss: 0.134\n",
      "[epoch: 6, batches:    64 -    79] train loss: 0.127\n",
      "[epoch: 6, batches:    80 -    95] train loss: 0.115\n",
      "[epoch: 6, batches:    96 -   111] train loss: 0.113\n",
      "[epoch: 6, batches:   112 -   127] train loss: 0.119\n",
      "[epoch: 6, batches:   128 -   143] train loss: 0.117\n",
      "[epoch: 6, batches:   144 -   159] train loss: 0.104\n",
      "Training in epoch 6 finished. Train loss: 0.1042090430855751]\n",
      "[Validation in epoch 6 finished. Validation loss: 0.100]\n",
      "  Epoch: 7\n",
      "[epoch: 7, batches:     0 -    15] train loss: 0.117\n",
      "[epoch: 7, batches:    16 -    31] train loss: 0.114\n",
      "[epoch: 7, batches:    32 -    47] train loss: 0.119\n",
      "[epoch: 7, batches:    48 -    63] train loss: 0.116\n",
      "[epoch: 7, batches:    64 -    79] train loss: 0.103\n",
      "[epoch: 7, batches:    80 -    95] train loss: 0.117\n",
      "[epoch: 7, batches:    96 -   111] train loss: 0.115\n",
      "[epoch: 7, batches:   112 -   127] train loss: 0.116\n",
      "[epoch: 7, batches:   128 -   143] train loss: 0.111\n",
      "[epoch: 7, batches:   144 -   159] train loss: 0.115\n",
      "Training in epoch 7 finished. Train loss: 0.11540158838033676]\n",
      "[Validation in epoch 7 finished. Validation loss: 0.101]\n",
      "  Epoch: 8\n",
      "[epoch: 8, batches:     0 -    15] train loss: 0.104\n",
      "[epoch: 8, batches:    16 -    31] train loss: 0.106\n",
      "[epoch: 8, batches:    32 -    47] train loss: 0.110\n",
      "[epoch: 8, batches:    48 -    63] train loss: 0.100\n",
      "[epoch: 8, batches:    64 -    79] train loss: 0.105\n",
      "[epoch: 8, batches:    80 -    95] train loss: 0.097\n",
      "[epoch: 8, batches:    96 -   111] train loss: 0.108\n",
      "[epoch: 8, batches:   112 -   127] train loss: 0.101\n",
      "[epoch: 8, batches:   128 -   143] train loss: 0.103\n",
      "[epoch: 8, batches:   144 -   159] train loss: 0.093\n",
      "Training in epoch 8 finished. Train loss: 0.09261060040444136]\n",
      "[Validation in epoch 8 finished. Validation loss: 0.105]\n",
      "  Epoch: 9\n",
      "[epoch: 9, batches:     0 -    15] train loss: 0.099\n",
      "[epoch: 9, batches:    16 -    31] train loss: 0.100\n",
      "[epoch: 9, batches:    32 -    47] train loss: 0.106\n",
      "[epoch: 9, batches:    48 -    63] train loss: 0.093\n",
      "[epoch: 9, batches:    64 -    79] train loss: 0.102\n",
      "[epoch: 9, batches:    80 -    95] train loss: 0.097\n",
      "[epoch: 9, batches:    96 -   111] train loss: 0.099\n",
      "[epoch: 9, batches:   112 -   127] train loss: 0.097\n",
      "[epoch: 9, batches:   128 -   143] train loss: 0.103\n",
      "[epoch: 9, batches:   144 -   159] train loss: 0.101\n",
      "Training in epoch 9 finished. Train loss: 0.10069129895418882]\n",
      "[Validation in epoch 9 finished. Validation loss: 0.095]\n",
      "  Epoch: 10\n",
      "[epoch: 10, batches:     0 -    15] train loss: 0.097\n",
      "[epoch: 10, batches:    16 -    31] train loss: 0.097\n",
      "[epoch: 10, batches:    32 -    47] train loss: 0.094\n",
      "[epoch: 10, batches:    48 -    63] train loss: 0.098\n",
      "[epoch: 10, batches:    64 -    79] train loss: 0.103\n",
      "[epoch: 10, batches:    80 -    95] train loss: 0.096\n",
      "[epoch: 10, batches:    96 -   111] train loss: 0.098\n",
      "[epoch: 10, batches:   112 -   127] train loss: 0.096\n",
      "[epoch: 10, batches:   128 -   143] train loss: 0.092\n",
      "[epoch: 10, batches:   144 -   159] train loss: 0.098\n",
      "Training in epoch 10 finished. Train loss: 0.09769449010491371]\n",
      "[Validation in epoch 10 finished. Validation loss: 0.083]\n",
      "  Epoch: 11\n",
      "[epoch: 11, batches:     0 -    15] train loss: 0.091\n",
      "[epoch: 11, batches:    16 -    31] train loss: 0.087\n",
      "[epoch: 11, batches:    32 -    47] train loss: 0.093\n",
      "[epoch: 11, batches:    48 -    63] train loss: 0.094\n",
      "[epoch: 11, batches:    64 -    79] train loss: 0.091\n",
      "[epoch: 11, batches:    80 -    95] train loss: 0.092\n",
      "[epoch: 11, batches:    96 -   111] train loss: 0.099\n",
      "[epoch: 11, batches:   112 -   127] train loss: 0.109\n",
      "[epoch: 11, batches:   128 -   143] train loss: 0.096\n",
      "[epoch: 11, batches:   144 -   159] train loss: 0.092\n",
      "Training in epoch 11 finished. Train loss: 0.09185273014008999]\n",
      "[Validation in epoch 11 finished. Validation loss: 0.086]\n",
      "  Epoch: 12\n",
      "[epoch: 12, batches:     0 -    15] train loss: 0.086\n",
      "[epoch: 12, batches:    16 -    31] train loss: 0.093\n",
      "[epoch: 12, batches:    32 -    47] train loss: 0.088\n",
      "[epoch: 12, batches:    48 -    63] train loss: 0.090\n",
      "[epoch: 12, batches:    64 -    79] train loss: 0.088\n",
      "[epoch: 12, batches:    80 -    95] train loss: 0.085\n",
      "[epoch: 12, batches:    96 -   111] train loss: 0.095\n",
      "[epoch: 12, batches:   112 -   127] train loss: 0.100\n",
      "[epoch: 12, batches:   128 -   143] train loss: 0.093\n",
      "[epoch: 12, batches:   144 -   159] train loss: 0.088\n",
      "Training in epoch 12 finished. Train loss: 0.08797831647098064]\n",
      "[Validation in epoch 12 finished. Validation loss: 0.091]\n",
      "  Epoch: 13\n",
      "[epoch: 13, batches:     0 -    15] train loss: 0.091\n",
      "[epoch: 13, batches:    16 -    31] train loss: 0.085\n",
      "[epoch: 13, batches:    32 -    47] train loss: 0.087\n",
      "[epoch: 13, batches:    48 -    63] train loss: 0.086\n",
      "[epoch: 13, batches:    64 -    79] train loss: 0.091\n",
      "[epoch: 13, batches:    80 -    95] train loss: 0.087\n",
      "[epoch: 13, batches:    96 -   111] train loss: 0.087\n",
      "[epoch: 13, batches:   112 -   127] train loss: 0.092\n",
      "[epoch: 13, batches:   128 -   143] train loss: 0.093\n",
      "[epoch: 13, batches:   144 -   159] train loss: 0.088\n",
      "Training in epoch 13 finished. Train loss: 0.08841872122138739]\n",
      "[Validation in epoch 13 finished. Validation loss: 0.083]\n",
      "  Epoch: 14\n",
      "[epoch: 14, batches:     0 -    15] train loss: 0.085\n",
      "[epoch: 14, batches:    16 -    31] train loss: 0.090\n",
      "[epoch: 14, batches:    32 -    47] train loss: 0.083\n",
      "[epoch: 14, batches:    48 -    63] train loss: 0.094\n",
      "[epoch: 14, batches:    64 -    79] train loss: 0.085\n",
      "[epoch: 14, batches:    80 -    95] train loss: 0.091\n",
      "[epoch: 14, batches:    96 -   111] train loss: 0.088\n",
      "[epoch: 14, batches:   112 -   127] train loss: 0.086\n",
      "[epoch: 14, batches:   128 -   143] train loss: 0.085\n",
      "[epoch: 14, batches:   144 -   159] train loss: 0.091\n",
      "Training in epoch 14 finished. Train loss: 0.09119365038350224]\n",
      "[Validation in epoch 14 finished. Validation loss: 0.082]\n"
     ]
    }
   ],
   "source": [
    "# config params\n",
    "load_model = False\n",
    "model_name = 'basic_unet_128_local'\n",
    "axes = ['X', 'Y', 'Z']\n",
    "\n",
    "for axis in axes:\n",
    "    print(f'===== Training {model_name} for axis {axis} =====')\n",
    "\n",
    "    # networks params\n",
    "    network = BasicUNET(in_channels=1, classes=8)\n",
    "    optimizer_name = \"adam\"\n",
    "    learning_rate = 0.0005\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    batch_size = 32\n",
    "    epochs = 15\n",
    "    img_height = 128\n",
    "    img_width = 128\n",
    "\n",
    "    # data\n",
    "    train_transform = transforms.Compose([\n",
    "        \n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=50),\n",
    "        transforms.RandomResizedCrop(size=(configs.IMG_ORYG_HEIGHT, configs.IMG_ORYG_WIDTH), scale=(0.6, 1.0)),\n",
    "        transforms.Resize((img_height, img_width), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((img_height, img_width), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    ])\n",
    "    train_loader = load_BrainTissue_data(configs.DATA_2D_PATH, TRAIN_IDX_START, TRAIN_IDX_STOP, axis, train_transform, batch_size)\n",
    "    val_loader = load_BrainTissue_data(configs.DATA_2D_PATH, VAL_IDX_START, VAL_IDX_STOP, axis, val_transform, batch_size)\n",
    "\n",
    "    # save model params\n",
    "    save_params(\n",
    "        model_name=model_name,\n",
    "        axis=axis,\n",
    "        optimizer_name=optimizer_name,\n",
    "        loss_fn=str(loss_fn),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        img_height=img_height,\n",
    "        img_width=img_width,\n",
    "        parms_path=get_parms_path(model_name, axis)\n",
    "    )\n",
    "\n",
    "    # train network\n",
    "    train_network(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        network=network, \n",
    "        optimizer_name=optimizer_name, \n",
    "        learning_rate=learning_rate, \n",
    "        loss_fn=loss_fn, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        load_model=load_model,\n",
    "        model_path=get_model_path(model_name, axis),  \n",
    "        loss_path=get_loss_path(model_name, axis),\n",
    "        device=DEVICE\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 x Resnet-based Encoder Unet 64 x 64 (Cross Entropy Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/qubvel/segmentation_models.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/LucasFidon/GeneralizedWassersteinDiceLoss.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generalized_wasserstein_dice_loss.loss import GeneralizedWassersteinDiceLoss\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config params\n",
    "load_model = False\n",
    "model_name = 'UNetWithResnet34Encoder_64_diceceloss'\n",
    "axes = ['X', 'Y', 'Z']\n",
    "\n",
    "for axis in axes:\n",
    "    print(f'===== Training {model_name} for axis {axis} =====')\n",
    "\n",
    "    # networks params\n",
    "    network = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", activation=None, classes=8, in_channels=1)\n",
    "    optimizer_name = \"adam\"\n",
    "    learning_rate = 0.0005\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    batch_size = 32\n",
    "    epochs = 20\n",
    "    img_height = 64\n",
    "    img_width = 64\n",
    "\n",
    "    # data\n",
    "    train_transform = transforms.Compose([\n",
    "        \n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=50),\n",
    "        transforms.RandomResizedCrop(size=(configs.IMG_ORYG_HEIGHT, configs.IMG_ORYG_WIDTH), scale=(0.6, 1.0)),\n",
    "        transforms.Resize((img_height, img_width), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((img_height, img_width), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    ])\n",
    "    train_loader = load_BrainTissue_data(configs.DATA_2D_PATH, TRAIN_IDX_START, TRAIN_IDX_STOP, axis, train_transform, batch_size)\n",
    "    val_loader = load_BrainTissue_data(configs.DATA_2D_PATH, VAL_IDX_START, VAL_IDX_STOP, axis, val_transform, batch_size)\n",
    "\n",
    "    # save model params\n",
    "    save_params(\n",
    "        model_name=model_name,\n",
    "        axis=axis,\n",
    "        optimizer_name=optimizer_name,\n",
    "        loss_fn=str(loss_fn),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        img_height=img_height,\n",
    "        img_width=img_width,\n",
    "        parms_path=get_parms_path(model_name, axis)\n",
    "    )\n",
    "\n",
    "    # train network\n",
    "    train_network(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        network=network, \n",
    "        optimizer_name=optimizer_name, \n",
    "        learning_rate=learning_rate, \n",
    "        loss_fn=loss_fn, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        load_model=load_model,\n",
    "        model_path=get_model_path(model_name, axis),  \n",
    "        loss_path=get_loss_path(model_name, axis),\n",
    "        device=DEVICE\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 x Resnet-based Encoder Unet 64 x 64 (Dice + Cross Entropy Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceCrossEntropyLoss, self).__init__()\n",
    "        dist_mat = np.ones((8,8))  \n",
    "        dist_mat = dist_mat - np.diag([1]*8)\n",
    "        self.wass_loss = GeneralizedWassersteinDiceLoss(dist_matrix=dist_mat)\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        # dice\n",
    "        inputs = F.sigmoid(inputs)  \n",
    "        pred = torch.flatten(inputs, start_dim=-2)\n",
    "        grnd = torch.flatten(targets, start_dim=-2)\n",
    "        dice_loss = self.wass_loss(pred, grnd)\n",
    "        \n",
    "        # cross entropy\n",
    "        ce_loss = self.ce_loss(inputs, targets)\n",
    "        Dice_CE = ce_loss + dice_loss\n",
    "        \n",
    "        return Dice_CE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config params\n",
    "load_model = False\n",
    "model_name = 'UNetWithResnet34Encoder_64_diceceloss'\n",
    "axes = ['X', 'Y', 'Z']\n",
    "\n",
    "for axis in axes:\n",
    "    print(f'===== Training {model_name} for axis {axis} =====')\n",
    "\n",
    "    # networks params\n",
    "    network = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", activation=None, classes=8, in_channels=1)\n",
    "    optimizer_name = \"adam\"\n",
    "    learning_rate = 0.0005\n",
    "    loss_fn = DiceCrossEntropyLoss()\n",
    "    batch_size = 32\n",
    "    epochs = 20\n",
    "    img_height = 64\n",
    "    img_width = 64\n",
    "\n",
    "    # data\n",
    "    train_transform = transforms.Compose([\n",
    "        \n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=50),\n",
    "        transforms.RandomResizedCrop(size=(configs.IMG_ORYG_HEIGHT, configs.IMG_ORYG_WIDTH), scale=(0.6, 1.0)),\n",
    "        transforms.Resize((img_height, img_width), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((img_height, img_width), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    ])\n",
    "    train_loader = load_BrainTissue_data(configs.DATA_2D_PATH, TRAIN_IDX_START, TRAIN_IDX_STOP, axis, train_transform, batch_size)\n",
    "    val_loader = load_BrainTissue_data(configs.DATA_2D_PATH, VAL_IDX_START, VAL_IDX_STOP, axis, val_transform, batch_size)\n",
    "\n",
    "    # save model params\n",
    "    save_params(\n",
    "        model_name=model_name,\n",
    "        axis=axis,\n",
    "        optimizer_name=optimizer_name,\n",
    "        loss_fn=str(loss_fn),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        img_height=img_height,\n",
    "        img_width=img_width,\n",
    "        parms_path=get_parms_path(model_name, axis)\n",
    "    )\n",
    "\n",
    "    # train network\n",
    "    train_network(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader, \n",
    "        network=network, \n",
    "        optimizer_name=optimizer_name, \n",
    "        learning_rate=learning_rate, \n",
    "        loss_fn=loss_fn, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        load_model=load_model,\n",
    "        model_path=get_model_path(model_name, axis),  \n",
    "        loss_path=get_loss_path(model_name, axis),\n",
    "        device=DEVICE\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlmia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abecd8fa0cfcb7e84a890aab3b6220a2a5275616ec88b8965617552763a51580"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
